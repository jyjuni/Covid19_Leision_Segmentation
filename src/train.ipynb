{"cells":[{"cell_type":"markdown","metadata":{},"source":["# COVID-19 Lung Leision Segmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-22T15:09:20.043134Z","iopub.status.busy":"2022-03-22T15:09:20.042868Z","iopub.status.idle":"2022-03-22T15:09:20.048818Z","shell.execute_reply":"2022-03-22T15:09:20.048126Z","shell.execute_reply.started":"2022-03-22T15:09:20.043106Z"},"trusted":true},"outputs":[],"source":["import os\n","import glob\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import cv2\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.optim import Adam, SGD\n","from torch.utils.data import TensorDataset, DataLoader"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-22T15:09:20.061411Z","iopub.status.busy":"2022-03-22T15:09:20.061177Z","iopub.status.idle":"2022-03-22T15:09:20.065846Z","shell.execute_reply":"2022-03-22T15:09:20.065082Z","shell.execute_reply.started":"2022-03-22T15:09:20.061386Z"},"trusted":true},"outputs":[],"source":["cuda = torch.cuda.is_available()\n","print(\"GPU available:\", cuda)\n","torch.manual_seed(4460)\n","np.random.seed(4460)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-22T15:09:27.227368Z","iopub.status.busy":"2022-03-22T15:09:27.227058Z","iopub.status.idle":"2022-03-22T15:09:27.245832Z","shell.execute_reply":"2022-03-22T15:09:27.244876Z","shell.execute_reply.started":"2022-03-22T15:09:27.227329Z"},"trusted":true},"outputs":[],"source":["data_root_folder = '../input/singlecellsegmentation/SingleCellSegmentation/'\n","class BasicDataset(TensorDataset):\n","    # This function takes folder name ('train', 'valid', 'test') as input and creates an instance of BasicDataset according to that folder.\n","    # Also if you'd like to have less number of samples (for evaluation purposes), you may set the `n_sample` with an integer.\n","    def __init__(self, folder, n_sample=None, transforms=None):\n","        self.folder = os.path.join(data_root_folder, folder)\n","        self.imgs_dir = os.path.join(self.folder, 'image')\n","        self.masks_dir = os.path.join(self.folder, 'mask')\n","        \n","        self.imgs_file = sorted(glob.glob(os.path.join(self.imgs_dir, '*.png')))\n","        self.masks_file = sorted(glob.glob(os.path.join(self.masks_dir, '*.png')))\n","        self.transforms = transforms\n","        \n","        assert len(self.imgs_file) == len(self.masks_file), 'There are some missing images or masks in {0}'.format(folder)\n","        \n","        # If n_sample is not None (It has been set by the user)\n","        if not n_sample or n_sample > len(self.imgs_file):\n","            n_sample = len(self.imgs_file)\n","        \n","        self.n_sample = n_sample\n","        self.ids = list([i+1 for i in range(n_sample)])\n","            \n","    # This function returns the lenght of the dataset (AKA number of samples in that set)\n","    def __len__(self):\n","        return self.n_sample\n","    \n","    \n","    # This function takes an index (i) which is between 0 to `len(BasicDataset)` (The return of the previous function), then returns RGB image, \n","    # mask (Binary), and the index of the file name (Which we will use for visualization). The preprocessing step is also implemented in this function.\n","    def __getitem__(self, i):\n","        idx = self.ids[i]\n","        img = cv2.imread(os.path.join(self.imgs_dir, 'image_{0:04d}.png'.format(idx)), cv2.IMREAD_COLOR)\n","        mask = cv2.imread(os.path.join(self.masks_dir, 'mask_{0:04d}.png'.format(idx)), cv2.IMREAD_GRAYSCALE)\n","        \n","            \n","        # Convert BGR to RGB\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        \n","        '''[(Q1) Converting RGB image to grayscale image: your answer here]'''\n","        # https://docs.opencv.org/3.4/d8/d01/group__imgproc__color__conversions.html#ga397ae87e1288a81d2363b61574eb8cab\n","        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n","\n","        '''[(Q2) Applying histogram equalization to the grayscale image: your answer here]''' \n","        # https://docs.opencv.org/3.4/d6/dc7/group__imgproc__hist.html#ga7e54091f0c937d49bf84152a16f76d6e\n","        img = cv2.equalizeHist(img)\n","        \n","        if self.transforms:\n","            augmented = self.transforms(image=img, mask=mask)\n","        \n","        #Resize all images from 512 to 256 (H and W)\n","        img = cv2.resize(img, (256,256))\n","        mask = cv2.resize(mask, (256,256))\n","        \n","        # Scale between 0 to 1\n","        img = np.array(img) / 255.0\n","        mask = np.array(mask) / 255.0\n","        \n","        # Make sure that the mask are binary (0 or 1)\n","        mask[mask <= 0.5] = 0\n","        mask[mask > 0.5] = 1\n","        \n","        # Add an axis to the image array so that it is in [channel, height, width] format.\n","        img = np.expand_dims(img, axis=0)\n","        \n","#         # HWC to CHW\n","#         img = np.transpose(img, (2, 0, 1))\n","                    \n","        return {\n","            'image': torch.from_numpy(img).type(torch.FloatTensor),\n","            'mask': torch.from_numpy(mask).type(torch.LongTensor),\n","            'img_id': idx\n","        }"]},{"cell_type":"markdown","metadata":{},"source":["Now we can create our three datasets and display the number of samples in each set in a pythonic way."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-22T15:09:27.247832Z","iopub.status.busy":"2022-03-22T15:09:27.247307Z","iopub.status.idle":"2022-03-22T15:09:27.515983Z","shell.execute_reply":"2022-03-22T15:09:27.515304Z","shell.execute_reply.started":"2022-03-22T15:09:27.247795Z"},"trusted":true},"outputs":[],"source":["# Create train, validation, and test dataset instances\n","train_dataset = BasicDataset('train')\n","valid_dataset = BasicDataset('valid')\n","test_dataset = BasicDataset('test')\n","\n","\n","plt.figure(figsize=(12,8))\n","plt.title('Data split distribution')\n","plt.bar(0, len(train_dataset), label='Train')\n","plt.bar(1, len(valid_dataset), label='Validation')\n","plt.bar(2, len(test_dataset), label='Test')\n","plt.ylabel('Number of samples')\n","plt.xticks([0,1,2],['Train', 'Validation', 'Test'])\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["Also, let's check if our `BasicDataset` implementation works by pulling out a random sample of the training set.\n","\n","(Don't forget that we need to reverse some of the preprocessing steps, like changing the axis format and rescaling the image intensity to `[0, 255]`)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-22T15:09:27.517441Z","iopub.status.busy":"2022-03-22T15:09:27.517053Z","iopub.status.idle":"2022-03-22T15:09:27.978679Z","shell.execute_reply":"2022-03-22T15:09:27.97807Z","shell.execute_reply.started":"2022-03-22T15:09:27.517406Z"},"trusted":true},"outputs":[],"source":["sample = np.random.randint(0, len(train_dataset))\n","data = train_dataset.__getitem__(sample)\n","x = data['image']\n","y = data['mask']\n","idx = data['img_id']\n","\n","print(f'x shape is {x.shape}')\n","print(f'y shape is {y.shape}')\n","\n","plt.figure(figsize=(12, 8), dpi=100)\n","plt.suptitle(f'Sample {idx:04d}')\n","img = x[0]\n","mask = y\n","plt.subplot(1, 2, 1)\n","plt.title('Image')\n","plt.imshow(img, cmap='gray')\n","plt.axis('off')\n","plt.subplot(1, 2, 2)\n","plt.title('Mask')\n","plt.imshow(mask, cmap='gray')\n","plt.axis('off')\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["Now that we have made sure our dataset implementation works fine, we can make the `DataLoader` per each set. We will set the batch size as **4** for all sets.\n","\n","<span style=\"color:red;font-size:18px;\" font>Important Note</span>: For this tutorial, we choose to work with **1000** samples for training, **200** samples for validation, and **200** samples for testing to reduce the training time. In your final project, you should use the whole dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-22T15:09:27.980292Z","iopub.status.busy":"2022-03-22T15:09:27.979923Z","iopub.status.idle":"2022-03-22T15:09:28.060458Z","shell.execute_reply":"2022-03-22T15:09:28.05972Z","shell.execute_reply.started":"2022-03-22T15:09:27.980255Z"},"trusted":true},"outputs":[],"source":["# Re-create train, validation, and test dataset instances to reduce the number of samples and expedite the training process.\n","train_dataset = BasicDataset('train', n_sample=1000)\n","valid_dataset = BasicDataset('valid', n_sample=200)\n","test_dataset = BasicDataset('test', n_sample=200)\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2, pin_memory=True)\n","valid_dataloader = DataLoader(valid_dataset, batch_size=4, num_workers=2, pin_memory=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=4, num_workers=2, pin_memory=True)"]},{"cell_type":"markdown","metadata":{},"source":["### 2. Implement U-Net model (Modified version)\n","\n","Now that we have set up our data loaders, we can implement the architecture.\n","\n","**We provided the code (Class UNet) for the following architecture**:\n","\n","<div align=\"center\">\n","  <img width=\"800px\" src=\"https://github.com/soroush361/AoE_BME/blob/main/modified_UNet_arch_2.png?raw=true\" />\n","</div>\n","\n","\n","**You are asked to modifed the provided code to implement the following architecture: \n","**\n","<div align=\"center\">\n","  <img width=\"800px\" src=\"https://raw.githubusercontent.com/XuzheZ/PTNet3D/main/Picture1.png\" />\n","</div>\n","\n","\n","To implement this modified U-Net, we first define four blocks that we will use multiple times while designing the complete architecture. \\\n","`DoubleCov` is block that contains these layers: Conv2d->BatchNormalization->ReLU->Conv2d->BatchNormalization->ReLU \\\n","`Down` is a downsampling block that contains Maxpooling and `DoubleConv` after Maxpooling. (Decoding layers) \\\n","`Up` is an upsampling block that upsamples the input then pass it through a `DoubleConv.` (Encoding Layers) \\\n","`OutConv` is just a $(1\\times1)$ 2D convolution followed by a Sigmoid activation that serves as an output layer in our U-Net model.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-22T15:09:28.061989Z","iopub.status.busy":"2022-03-22T15:09:28.061718Z","iopub.status.idle":"2022-03-22T15:09:28.076079Z","shell.execute_reply":"2022-03-22T15:09:28.07545Z","shell.execute_reply.started":"2022-03-22T15:09:28.061955Z"},"trusted":true},"outputs":[],"source":["######################################## Double Convolution\n","class DoubleConv(nn.Module):\n","    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n","\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.double_conv = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True), \n","            # nn.LeakyReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","            # nn.LeakyReLU(inplace=True),\n","        )\n","\n","    def forward(self, x):\n","        return self.double_conv(x)\n","    \n","    \n","######################################## Maxpooling followed by Double Convolution\n","class Down(nn.Module):\n","    \"\"\"Downscaling with maxpool then double conv\"\"\"\n","\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.maxpool_conv = nn.Sequential(\n","            nn.MaxPool2d(2),\n","            DoubleConv(in_channels, out_channels)\n","        )\n","\n","    def forward(self, x):\n","        return self.maxpool_conv(x)\n","\n","\n","######################################## Upsampling followed by Double Convolution\n","class Up(nn.Module):\n","    \"\"\"Upscaling then double conv\"\"\"\n","\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.up_conv = nn.Sequential(\n","            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n","            nn.Conv2d(in_channels, out_channels, kernel_size=1, padding=0),\n","        ) \n","        self.conv = DoubleConv(out_channels * 2, out_channels)\n","\n","\n","    def forward(self, x1, x2):\n","        x1 = self.up_conv(x1)\n","        x = torch.cat([x1, x2], dim=1)\n","        x = self.conv(x)\n","        return x\n","\n","######################################## Output layer (1x1 Convolution followed by SoftMax activation)\n","class OutConv(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(OutConv, self).__init__()\n","        self.conv_sigmoid = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=1),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        return self.conv_sigmoid(x)"]},{"cell_type":"markdown","metadata":{},"source":["Now we can mix the above modules to build our architecture.\n","\n","We will assign `name`, `n_channels`, and `n_classes` to our implementation for organization purposes. In this case, we may set `name` as an arbitrary name (e.g., 'MyUNet'), `n_channels` must be **1** (Since the input image is gray), and `n_classes` must be **2** (One channel to show the likelihood for background and one for the cells)."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-22T15:09:28.078144Z","iopub.status.busy":"2022-03-22T15:09:28.077291Z","iopub.status.idle":"2022-03-22T15:09:28.09219Z","shell.execute_reply":"2022-03-22T15:09:28.091309Z","shell.execute_reply.started":"2022-03-22T15:09:28.078107Z"},"trusted":true},"outputs":[],"source":["class UNet(nn.Module):\n","    \n","\n","    \n","    def __init__(self, name, n_channels, n_classes):\n","        super(UNet, self).__init__()\n","        self.name = name\n","        self.n_channels = n_channels\n","        self.n_classes = n_classes\n","        '''[(Q3) Adding additional encoding and decoding layers below]'''\n","        self.inputL = DoubleConv(n_channels, 64)\n","        self.down1 = Down(64, 128)\n","        self.down2 = Down(128, 256)\n","        self.down3 = Down(256, 512)\n","        self.down4 = Down(512, 512)\n","        self.down5 = Down(512, 1024)\n","        \n","        \n","        self.up1 = Up(1024, 512)\n","        self.up2 = Up(512, 512)\n","        self.up3 = Up(512, 256)\n","        self.up4 = Up(256, 128)\n","        self.up5 = Up(128, 64)\n","        self.outputL = OutConv(64, n_classes)\n","        \n","        '''[(Q3) Modify the forward module below]'''\n","    def forward(self, x):\n","        x1 = self.inputL(x)\n","        x2 = self.down1(x1)\n","        x3 = self.down2(x2)\n","        x4 = self.down3(x3)\n","        x5 = self.down4(x4)\n","        b = self.down5(x5)\n","        \n","        x = self.up1(b, x5)\n","        x = self.up2(x, x4)\n","        x = self.up3(x, x3)\n","        x = self.up4(x, x2)\n","        x = self.up5(x, x1)\n","        \n","        x = self.outputL(x)\n","        \n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["Now we can create an instance of our implemented model."]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2022-03-22T15:09:28.094326Z","iopub.status.busy":"2022-03-22T15:09:28.093399Z","iopub.status.idle":"2022-03-22T15:09:31.313447Z","shell.execute_reply":"2022-03-22T15:09:31.312718Z","shell.execute_reply.started":"2022-03-22T15:09:28.09429Z"},"trusted":true},"outputs":[],"source":["# define the channel number first\n","inp_channel = 1\n","opt_channel = 2\n","my_UNet = UNet('MyUNet', inp_channel, opt_channel)\n","my_UNet.cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-22T15:09:31.315209Z","iopub.status.busy":"2022-03-22T15:09:31.314786Z","iopub.status.idle":"2022-03-22T15:09:31.322565Z","shell.execute_reply":"2022-03-22T15:09:31.321703Z","shell.execute_reply.started":"2022-03-22T15:09:31.315168Z"},"trusted":true},"outputs":[],"source":["#'''[(Q4) Printing the parameter number]'''\n","# type(all_params[0])\n","# torch.numel?  \n","# https://pytorch.org/docs/stable/generated/torch.numel.html\n","all_params = [param.numel() for param in my_UNet.parameters() if param.requires_grad]\n","print(\"total model parameters:\", sum(all_params))"]},{"cell_type":"markdown","metadata":{},"source":["Although we have not trained our model, we may see the output with random weights. Thus, we will pull a batch of test data loader, get the network's output, and plot it."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-22T15:09:31.327049Z","iopub.status.busy":"2022-03-22T15:09:31.326521Z","iopub.status.idle":"2022-03-22T15:09:38.293309Z","shell.execute_reply":"2022-03-22T15:09:38.29232Z","shell.execute_reply.started":"2022-03-22T15:09:31.32701Z"},"trusted":true},"outputs":[],"source":["# Take the first batch\n","for batch in test_dataloader:\n","    sample_batch = batch\n","    break\n","    \n","# Generat network prediction\n","with torch.no_grad():\n","    y_pred = my_UNet(sample_batch['image'].cuda())\n","\n","# Print the shapes of the images, masks, predicted masks\n","print('Sample batch \\'image \\'shape is: {0}\\nSample batch \\'mask\\' shape is: {1}\\nPredicted mask shape is: {2}'.format(sample_batch['image'].shape, \n","                                                                                                                       sample_batch['mask'].shape,\n","                                                                                                                       y_pred.shape\n","                                                                                                                      ))\n","\n","# Conver Pytorch tensor to numpy array then reverse the preprocessing steps\n","img = (sample_batch['image'][0][0].numpy() * 255).astype('uint8')\n","msk = (sample_batch['mask'][0].numpy() * 255).astype('uint8')\n","\n","# Using `np.argmax()`, we may choose the maximum likelihood to assign a label for each pixel\n","pred_msk_binary = (np.argmax(y_pred.cpu().numpy()[0], axis=0) * 255).astype('uint8')\n","# pred_msk_binary = ((y_pred.cpu().numpy()[0][0,:,:] > 0.5) * 255).astype('uint8')\n","\n","# Take the image id for display\n","img_id = sample_batch['img_id'][0]\n","\n","# Plot the smaple, ground truth, the prediction probability map, and the final predicted mask\n","plt.figure(figsize=(24,18))\n","plt.suptitle(f'Test sample Image {img_id}', fontsize=18)\n","\n","plt.subplot(2,3,1)\n","plt.title('Input Image', fontsize=15)\n","plt.imshow(img, cmap='gray')\n","plt.axis('off')\n","\n","plt.subplot(2,3,2)\n","plt.title('Ground Truth', fontsize=15)\n","plt.imshow(msk, cmap='gray')\n","plt.axis('off')\n","\n","\n","plt.subplot(2,3,3)\n","plt.title('Non-trained Binary Prediction', fontsize=15)\n","plt.imshow(pred_msk_binary, cmap='gray')\n","plt.axis('off')\n","\n","input_overlayed_GT = img.copy()\n","input_overlayed_GT = cv2.cvtColor(input_overlayed_GT, cv2.COLOR_GRAY2RGB)\n","input_overlayed_GT[msk == 255, :] = [0, 255, 0]\n","plt.subplot(2,3,4)\n","plt.title('Input Image overlayed with Ground Truth', fontsize=15)\n","plt.imshow(input_overlayed_GT)\n","plt.axis('off')\n","\n","input_overlayed_Pred = img.copy()\n","input_overlayed_Pred = cv2.cvtColor(input_overlayed_Pred, cv2.COLOR_GRAY2RGB)\n","input_overlayed_Pred[pred_msk_binary == 255, :] = [255, 0, 0]\n","plt.subplot(2,3,5)\n","plt.title('Input Image overlayed with Prediction', fontsize=15)\n","plt.imshow(input_overlayed_Pred)\n","plt.axis('off')\n","\n","GT_overlayed_prediction = np.zeros_like(img)\n","GT_overlayed_prediction = cv2.cvtColor(GT_overlayed_prediction, cv2.COLOR_GRAY2RGB)\n","GT_overlayed_prediction[msk == 255, 1] = 255\n","GT_overlayed_prediction[pred_msk_binary == 255, 0] = 255\n","plt.subplot(2,3,6)\n","plt.title('Ground Truth overlayed with Prediction', fontsize=15)\n","plt.imshow(GT_overlayed_prediction)\n","plt.axis('off')\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2021-10-30T22:12:50.781017Z","iopub.status.busy":"2021-10-30T22:12:50.780538Z","iopub.status.idle":"2021-10-30T22:12:50.786107Z","shell.execute_reply":"2021-10-30T22:12:50.785164Z","shell.execute_reply.started":"2021-10-30T22:12:50.78097Z"}},"source":["As you can see, the predicted mask is not nearly close to the ground truth because we didn't train the network!"]},{"cell_type":"markdown","metadata":{},"source":["### 3. Train the model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-22T15:09:38.295831Z","iopub.status.busy":"2022-03-22T15:09:38.295337Z","iopub.status.idle":"2022-03-22T15:09:38.303646Z","shell.execute_reply":"2022-03-22T15:09:38.302902Z","shell.execute_reply.started":"2022-03-22T15:09:38.29579Z"},"trusted":true},"outputs":[],"source":["optimizer = torch.optim.Adam(my_UNet.parameters(), lr=0.001)\n","loss_function = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-22T15:09:38.317343Z","iopub.status.busy":"2022-03-22T15:09:38.316718Z","iopub.status.idle":"2022-03-22T15:09:38.360534Z","shell.execute_reply":"2022-03-22T15:09:38.359701Z","shell.execute_reply.started":"2022-03-22T15:09:38.317306Z"},"trusted":true},"outputs":[],"source":["# Define a function that computes the Jaccard score for binary segmentation\n","def jaccard_coeff_binary(y_pred, y_true):\n","        '''[(Q5) Your answer here - hint: check the equation of Jaccard Index here:https://en.wikipedia.org/wiki/Jaccard_index, do not use predefined jaccard index functions provided in any libraries ]'''\n","        eps = 0.0001\n","        inter = torch.dot(y_pred.view(-1).float(), y_true.view(-1).float())\n","        sums = torch.sum(y_pred.float()) + torch.sum(y_true.float())\n","        jaccard_index = ((inter.float() + eps) / (sums.float() - inter.float() + eps))\n","        return jaccard_index.cpu().numpy()\n","\n","# Define a function that computes the DICE score for binary segmentation\n","def dice_coeff_binary(y_pred, y_true):\n","        \"\"\"Values must be only zero or one.\"\"\"\n","        eps = 0.0001\n","        inter = torch.dot(y_pred.view(-1).float(), y_true.view(-1).float())\n","        union = torch.sum(y_pred.float()) + torch.sum(y_true.float())\n","        return ((2 * inter.float() + eps) / (union.float() + eps)).cpu().numpy()\n","    \n","\n","# The training function\n","def train_net(net, epochs, train_dataloader, valid_dataloader, optimizer, loss_function):\n","    trigger_times, patience = 0, 5\n","    last_loss = float(\"inf\")\n","    if not os.path.isdir('{0}'.format(net.name)):\n","        os.mkdir('{0}'.format(net.name))\n","    \n","    n_train = len(train_dataloader)\n","    n_valid = len(valid_dataloader)    \n","    \n","    train_loss = list()\n","    valid_loss = list()\n","    train_dice = list()\n","    valid_dice = list()\n","    train_jaccard = list()\n","    valid_jaccard = list()\n","    \n","    for epoch in range(epochs):\n","        \n","        ################################################################################################################################\n","        ########################################################### Training ###########################################################\n","        ################################################################################################################################\n","        net.train()\n","        train_batch_loss = list()\n","        train_batch_dice = list()\n","        train_batch_jaccard = list()\n","        \n","        for i, batch in enumerate(train_dataloader):\n","\n","            # Load a batch and pass it to the GPU\n","            imgs = batch['image'].cuda()\n","            true_masks = batch['mask'].cuda()\n","\n","            # Produce the estimated mask using current weights\n","            y_pred = net(imgs)\n","\n","            # Compute the loss for this batch and append it to the epoch loss\n","            loss = loss_function(y_pred, true_masks)\n","            batch_loss = loss.item()\n","            train_batch_loss.append(batch_loss)\n","\n","            # Make the binary mask to compute the DICE score. Since the y_pred is a Pytoch tensor, we use `torch.argmax()` instead of `np.argmax()`.\n","            # the axis must be 1 instead of 0 because the format is [batch, channel, height, width]\n","            pred_binary = torch.argmax(y_pred, axis=1)\n","            \n","            # Compute the DICE score for this batch and append it to the epoch dice\n","            batch_dice_score = dice_coeff_binary(pred_binary, true_masks)\n","            train_batch_dice.append(batch_dice_score)\n","            \n","            # Compute the Jaccard score here and \n","            batch_jaccard_score = jaccard_coeff_binary(pred_binary, true_masks)      \n","            train_batch_jaccard.append(batch_jaccard_score)\n","            \n","\n","            # Reset gradient values\n","            optimizer.zero_grad()\n","\n","            # Compute the backward losses\n","            loss.backward()\n","\n","            # Update the weights\n","            optimizer.step()\n","            \n","            # Print the progress\n","            print(f'EPOCH {epoch + 1}/{epochs} - Training Batch {i+1}/{n_train} - Loss: {batch_loss}, DICE score: {batch_dice_score}, Jaccard score: {batch_jaccard_score}            ', end='\\r')\n","            \n","\n","        \n","        average_training_loss = np.array(train_batch_loss).mean()\n","        average_training_dice = np.array(train_batch_dice).mean()\n","        average_training_jaccard = np.array(train_batch_jaccard).mean()\n","        train_loss.append(average_training_loss)\n","        train_dice.append(average_training_dice)\n","        train_jaccard.append(average_training_jaccard)\n","        \n","        ################################################################################################################################\n","        ########################################################## Validation ##########################################################\n","        ################################################################################################################################\n","        \n","        net.eval()\n","        valid_batch_loss = list()\n","        valid_batch_dice = list()\n","        valid_batch_jaccard = list()\n","        \n","        # This part is almost the same as training with the difference that we will set all layers to evaluation mode (effects some layers such as BN and Dropout) and also\n","        # we don't need to calculate the gradient since we are only evaluating current state of the model. This will speed up the process and cause it to consume less memory.\n","        with torch.no_grad():\n","            for i, batch in enumerate(valid_dataloader):\n","\n","                # Load a batch and pass it to the GPU\n","                imgs = batch['image'].cuda()\n","                true_masks = batch['mask'].cuda()\n","\n","                # Produce the estimated mask using current weights\n","                y_pred = net(imgs)\n","\n","                # Compute the loss for this batch and append it to the epoch loss\n","                loss = loss_function(y_pred, true_masks)\n","                batch_loss = loss.item()\n","                valid_batch_loss.append(batch_loss)\n","\n","                # Make the binary mask to compute the DICE score. Since the y_pred is a Pytoch tensor, we use `torch.argmax()` instead of `np.argmax()`.\n","                # the axis must be 1 instead of 0 because the format is [batch, channel, height, width]\n","                pred_binary = torch.argmax(y_pred, axis=1)\n","\n","                # Compute the DICE score for this batch and append it to the epoch dice\n","                batch_dice_score = dice_coeff_binary(pred_binary, true_masks)\n","                valid_batch_dice.append(batch_dice_score)\n","                \n","                # Compute the Jaccard score here and append the score to the list\n","                batch_jaccard_score = jaccard_coeff_binary(pred_binary, true_masks)\n","                valid_batch_jaccard.append(batch_jaccard_score)\n","\n","                # Print the progress\n","                print(f'EPOCH {epoch + 1}/{epochs} - Validation Batch {i+1}/{n_valid} - Loss: {batch_loss}, DICE score: {batch_dice_score}, Jaccard score: {batch_jaccard_score}            ', end='\\r')\n","        \n","            \n","\n","            \n","        average_validation_loss = np.array(valid_batch_loss).mean()\n","        average_validation_dice = np.array(valid_batch_dice).mean()\n","        average_validation_jaccard = np.array(valid_batch_jaccard).mean()\n","        valid_loss.append(average_validation_loss)\n","        valid_dice.append(average_validation_dice)\n","        valid_jaccard.append(average_validation_jaccard)\n","        \n","        # Early stopping: https://clay-atlas.com/us/blog/2021/08/25/pytorch-en-early-stopping/\n","        if average_validation_loss > last_loss:\n","            trigger_times += 1\n","            print('trigger times:', trigger_times)\n","\n","            if trigger_times >= patience:\n","                print('Early stopping!\\nStart to test process.')\n","                return train_loss, train_dice, train_jaccard, valid_loss, valid_dice, valid_jaccard\n","\n","        else:\n","            print('trigger times: 0')\n","            trigger_times = 0\n","        \n","        last_loss = average_validation_loss\n","        \n","        print(f'EPOCH {epoch + 1}/{epochs} - Training Loss: {average_training_loss}, Training DICE score: {average_training_dice}, Training Jaccard score: {average_training_jaccard}, Validation Loss: {average_validation_loss}, Validation DICE score: {average_validation_dice}, Validation Jaccard score: {average_validation_jaccard}')\n","\n","        ################################################################################################################################\n","        ###################################################### Saveing Checkpoints #####################################################\n","        ################################################################################################################################\n","        torch.save(net.state_dict(), f'{net.name}/epoch_{epoch+1:03}.pth')\n","    \n","    return train_loss, train_dice, train_jaccard, valid_loss, valid_dice, valid_jaccard"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-22T15:09:38.362416Z","iopub.status.busy":"2022-03-22T15:09:38.361981Z","iopub.status.idle":"2022-03-22T15:19:48.661897Z","shell.execute_reply":"2022-03-22T15:19:48.661041Z","shell.execute_reply.started":"2022-03-22T15:09:38.362375Z"},"trusted":true},"outputs":[],"source":["EPOCHS = 10\n","train_loss, train_dice, train_jaccard, valid_loss, valid_dice, valid_jaccard = train_net(my_UNet, EPOCHS, train_dataloader, valid_dataloader, optimizer, loss_function)"]},{"cell_type":"markdown","metadata":{},"source":["### Display results"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-22T15:19:48.664208Z","iopub.status.busy":"2022-03-22T15:19:48.663635Z","iopub.status.idle":"2022-03-22T15:19:49.206677Z","shell.execute_reply":"2022-03-22T15:19:49.204916Z","shell.execute_reply.started":"2022-03-22T15:19:48.664165Z"},"trusted":true},"outputs":[],"source":["plt.figure(figsize=(18,8))\n","plt.suptitle('Learning Curve', fontsize=18)\n","\n","plt.subplot(1,3,1)\n","plt.plot(np.arange(EPOCHS)+1, train_loss, '-o', label='Training Loss')\n","plt.plot(np.arange(EPOCHS)+1, valid_loss, '-o', label='Validation Loss')\n","plt.xticks(np.arange(EPOCHS)+1)\n","plt.xlabel('Epoch', fontsize=15)\n","plt.ylabel('Loss', fontsize=15)\n","plt.legend()\n","\n","plt.subplot(1,3,2)\n","plt.plot(np.arange(EPOCHS)+1, train_dice, '-o', label='Training DICE score')\n","plt.plot(np.arange(EPOCHS)+1, valid_dice, '-o', label='Validation DICE score')\n","plt.xticks(np.arange(EPOCHS)+1)\n","plt.xlabel('Epoch', fontsize=15)\n","plt.ylabel('DICE score', fontsize=15)\n","plt.legend()\n","\n","plt.subplot(1,3,3)\n","plt.plot(np.arange(EPOCHS)+1, train_jaccard, '-o', label='Training Jaccard score')\n","plt.plot(np.arange(EPOCHS)+1, valid_jaccard, '-o', label='Validation Jaccard score')\n","plt.xticks(np.arange(EPOCHS)+1)\n","plt.xlabel('Epoch', fontsize=15)\n","plt.ylabel('Jaccard score', fontsize=15)\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["Then, let us see in which epoch the model obtained the highest validation DICE score and load the weights of that epoch as our best model weights."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-22T15:19:49.208839Z","iopub.status.busy":"2022-03-22T15:19:49.208303Z","iopub.status.idle":"2022-03-22T15:19:49.332467Z","shell.execute_reply":"2022-03-22T15:19:49.331621Z","shell.execute_reply.started":"2022-03-22T15:19:49.2088Z"},"trusted":true},"outputs":[],"source":["best_epoch = np.argmax(valid_dice) + 1 # The plus one is because the epochs starts at 1.\n","\n","print(f'Best epoch is epoch{best_epoch}')\n","\n","state_dict = torch.load(f'./MyUNet/epoch_{best_epoch:03}.pth')\n","\n","my_UNet.load_state_dict(state_dict)\n","my_UNet.cuda()"]},{"cell_type":"markdown","metadata":{},"source":["Now we can check the performance of the best model on our previously pulled example. (The same scripts must work!)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-22T15:19:49.334369Z","iopub.status.busy":"2022-03-22T15:19:49.33409Z","iopub.status.idle":"2022-03-22T15:19:51.059939Z","shell.execute_reply":"2022-03-22T15:19:51.059183Z","shell.execute_reply.started":"2022-03-22T15:19:49.334332Z"},"trusted":true},"outputs":[],"source":["# Take the first batch of test set\n","for batch in test_dataloader:\n","    sample_batch = batch\n","    break\n","    \n","# Generat network prediction\n","with torch.no_grad():\n","    y_pred = my_UNet(sample_batch['image'].cuda())\n","\n","# Print the shapes of the images, masks, predicted masks\n","print('Sample batch \\'image \\'shape is: {0}\\nSample batch \\'mask\\' shape is: {1}\\nPredicted mask shape is: {2}'.format(sample_batch['image'].shape, \n","                                                                                                                       sample_batch['mask'].shape,\n","                                                                                                                       y_pred.shape\n","                                                                                                                      ))\n","\n","# Conver Pytorch tensor to numpy array then reverse the preprocessing steps\n","img = (sample_batch['image'][0][0].numpy() * 255).astype('uint8')\n","msk = (sample_batch['mask'][0].numpy() * 255).astype('uint8')\n","\n","# Using `np.argmax()`, we may choose the maximum likelihood to assign a label for each pixel\n","pred_msk_binary = (np.argmax(y_pred.cpu().numpy()[0], axis=0) * 255).astype('uint8')\n","# pred_msk_binary = ((y_pred.cpu().numpy()[0][0,:,:] > 0.5) * 255).astype('uint8')\n","\n","# Take the image id for display\n","img_id = sample_batch['img_id'][0]\n","\n","# Plot the smaple, ground truth, the prediction probability map, and the final predicted mask\n","plt.figure(figsize=(24,18))\n","plt.suptitle(f'Test sample Image {img_id}', fontsize=18)\n","\n","plt.subplot(2,3,1)\n","plt.title('Input Image', fontsize=15)\n","plt.imshow(img, cmap='gray')\n","plt.axis('off')\n","\n","plt.subplot(2,3,2)\n","plt.title('Ground Truth', fontsize=15)\n","plt.imshow(msk, cmap='gray')\n","plt.axis('off')\n","\n","\n","plt.subplot(2,3,3)\n","plt.title('Final Binary Prediction', fontsize=15)\n","plt.imshow(pred_msk_binary, cmap='gray')\n","plt.axis('off')\n","\n","input_overlayed_GT = img.copy()\n","input_overlayed_GT = cv2.cvtColor(input_overlayed_GT, cv2.COLOR_GRAY2RGB)\n","input_overlayed_GT[msk == 255, :] = [0, 255, 0]\n","plt.subplot(2,3,4)\n","plt.title('Input Image overlayed with Ground Truth', fontsize=15)\n","plt.imshow(input_overlayed_GT)\n","plt.axis('off')\n","\n","input_overlayed_Pred = img.copy()\n","input_overlayed_Pred = cv2.cvtColor(input_overlayed_Pred, cv2.COLOR_GRAY2RGB)\n","input_overlayed_Pred[pred_msk_binary == 255, :] = [255, 0, 0]\n","plt.subplot(2,3,5)\n","plt.title('Input Image overlayed with Prediction', fontsize=15)\n","plt.imshow(input_overlayed_Pred)\n","plt.axis('off')\n","\n","GT_overlayed_prediction = np.zeros_like(img)\n","GT_overlayed_prediction = cv2.cvtColor(GT_overlayed_prediction, cv2.COLOR_GRAY2RGB)\n","GT_overlayed_prediction[msk == 255, 1] = 255\n","GT_overlayed_prediction[pred_msk_binary == 255, 0] = 255\n","plt.subplot(2,3,6)\n","plt.title('Ground Truth overlayed with Prediction', fontsize=15)\n","plt.imshow(GT_overlayed_prediction)\n","plt.axis('off')\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["As it is clear, the model is predicting the ground truth much better compared to before training.\n","\n","However, we need to compute the overall performance of the model on all test samples. Then, similar to the `train_net` function, we can define a `test_net` function that tests our model on test samples and save the prediction masks in the `/kaggle/working/pred_mask` folder.\n","\n","This function takes the following arguments:\n","\n","1. `net`: The model we want to test.\n","2. `test_dataloader`: The `DataLoader` for the test set.\n","3. `loss_function`: The loss function to calculate the loss.\n","\n","This function returns:\n","1. `test_loss`: The average test loss.\n","2. `test_dice`: The average test DICE score.\n","3. `test_jaccard`: The average test Jaccard score.\n","4. `test_accuracy`: The overall accuracy of the model.\n","5. `test_CM`: The normalized confusion matrix of the model.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-22T15:19:51.061483Z","iopub.status.busy":"2022-03-22T15:19:51.061222Z","iopub.status.idle":"2022-03-22T15:19:51.097765Z","shell.execute_reply":"2022-03-22T15:19:51.096799Z","shell.execute_reply.started":"2022-03-22T15:19:51.061451Z"},"trusted":true},"outputs":[],"source":["def test_net(net, test_dataloader, loss_function):\n","    # Create the pred_mask folder\n","    if not os.path.isdir('/kaggle/working/pred_mask'):\n","        os.mkdir('/kaggle/working/pred_mask')\n","    \n","    net.eval()\n","    \n","    n_test = len(test_dataloader)\n","    test_batch_loss = list()\n","    test_batch_dice = list()\n","    test_batch_jaccard = list()\n","    test_batch_accuray = list()\n","    test_batch_CM = list()\n","\n","    # This part is almost the same as the validation loop in `train_net` function. \n","    # The difference is that we will calculate the accuracy and confusion matrix per each batch and save the predicted images.\n","    with torch.no_grad():\n","        for i, batch in enumerate(test_dataloader):\n","\n","            # Load a batch and pass it to the GPU\n","            imgs = batch['image'].cuda()\n","            true_masks = batch['mask'].cuda()\n","            img_ids = batch['img_id'].numpy().astype('int')\n","\n","            # Produce the estimated mask using current weights\n","            y_pred = net(imgs)\n","\n","            # Compute the loss for this batch and append it to the epoch loss\n","            loss = loss_function(y_pred, true_masks)\n","            batch_loss = loss.item()\n","            test_batch_loss.append(batch_loss)\n","\n","            # Make the binary mask to compute the DICE score. Since the y_pred is a Pytoch tensor, we use `torch.argmax()` instead of `np.argmax()`.\n","            # the axis must be 1 instead of 0 because the format is [batch, channel, height, width]\n","            pred_binary = torch.argmax(y_pred, axis=1)\n","\n","            # Compute the DICE score for this batch and append it to the epoch dice\n","            batch_dice_score = dice_coeff_binary(pred_binary, true_masks)\n","            test_batch_dice.append(batch_dice_score)\n","            \n","            # Compute the Jaccard score for this batch and append it to the epoch dice\n","            batch_jaccard_score = jaccard_coeff_binary(pred_binary, true_masks)\n","            test_batch_jaccard.append(batch_jaccard_score)\n","            \n","            # Save the predicted masks\n","            for idx, pred_msk in enumerate(pred_binary):\n","                cv2.imwrite(f'/kaggle/working/pred_mask/pred_mask_{img_ids[idx]:04}.png', pred_msk.cpu().numpy())\n","            \n","            # Vectorize the true mask and predicted mask for this batch\n","            vectorize_true_masks = true_masks.view(-1).cpu().numpy()\n","            vectorize_pred_masks = pred_binary.view(-1).cpu().numpy()\n","            \n","            # Compute the accuracy for this batch and append to the overall list\n","            batch_accuracy = accuracy_score(vectorize_true_masks, vectorize_pred_masks)\n","            test_batch_accuray.append(batch_accuracy)\n","            \n","            # Compute the normalized confusion matrix for this batch and append to the overall list\n","            batch_CM = confusion_matrix(vectorize_true_masks, vectorize_pred_masks, normalize='true', labels=[0, 1])\n","            test_batch_CM.append(batch_CM)\n","\n","            # Print the progress\n","            print(f'Test Batch {i+1}/{n_test} - Loss: {batch_loss}, DICE score: {batch_dice_score}, Jaccard score: {batch_jaccard_score}, Accuracy: {batch_accuracy}', end='\\r')\n","\n","    test_loss = np.array(test_batch_loss).mean()\n","    test_dice = np.array(test_batch_dice).mean()\n","    test_jaccard = np.array(test_batch_jaccard).mean()\n","    test_accuracy = np.array(test_batch_accuray).mean()\n","    test_CM = np.array(test_batch_CM).mean(axis=0)\n","    \n","    return test_loss, test_dice, test_jaccard, test_accuracy, test_CM"]},{"cell_type":"markdown","metadata":{},"source":["Let us use the function and see how it works!\n","\n","Note: The accuracy and confusion matrix are computed on the CPU; thus, this function might be slower."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-22T15:19:51.099817Z","iopub.status.busy":"2022-03-22T15:19:51.099228Z","iopub.status.idle":"2022-03-22T15:20:11.452508Z","shell.execute_reply":"2022-03-22T15:20:11.451505Z","shell.execute_reply.started":"2022-03-22T15:19:51.09978Z"},"trusted":true},"outputs":[],"source":["test_loss, test_dice, test_jaccard, test_accuracy, test_CM = test_net(my_UNet, test_dataloader, loss_function)\n","\n","print(f'Test Loss: {test_loss}, Test DICE score: {test_dice}, Test Jaccard score: {test_jaccard}, Test overall accuracy: {test_accuracy}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-22T15:20:11.454309Z","iopub.status.busy":"2022-03-22T15:20:11.453982Z","iopub.status.idle":"2022-03-22T15:20:11.719713Z","shell.execute_reply":"2022-03-22T15:20:11.719045Z","shell.execute_reply.started":"2022-03-22T15:20:11.454272Z"},"trusted":true},"outputs":[],"source":["df_cm = pd.DataFrame(test_CM, index = ['Background', 'Cell'],\n","                     columns = ['Background', 'Cell'])\n","plt.figure(figsize = (12,10))\n","plt.title('Confusion matrix')\n","sns.heatmap(df_cm, annot = True, fmt='.2%', annot_kws = {\"size\": 15})\n","plt.ylim([0, 2]);\n","plt.ylabel('True labels');\n","plt.xlabel('predicted labels');"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
